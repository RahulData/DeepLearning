{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prices Prediction Using Keras Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('NSE-TATAGLOBAL.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
       " 0  2018-09-28  234.05  235.95  230.20  233.50  233.75               3069914   \n",
       " 1  2018-09-27  234.55  236.80  231.10  233.80  233.25               5082859   \n",
       " 2  2018-09-26  240.00  240.00  232.50  235.00  234.25               2240909   \n",
       " 3  2018-09-25  233.30  236.75  232.00  236.25  236.10               2349368   \n",
       " 4  2018-09-24  233.55  239.20  230.75  234.00  233.30               3423509   \n",
       " \n",
       "    Turnover (Lacs)  \n",
       " 0          7162.35  \n",
       " 1         11859.95  \n",
       " 2          5248.60  \n",
       " 3          5503.90  \n",
       " 4          7999.55  ,\n",
       "             Date   Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
       " 2030  2010-07-27  117.6  119.50  112.00  118.80  118.65                586100   \n",
       " 2031  2010-07-26  120.1  121.00  117.10  117.10  117.60                658440   \n",
       " 2032  2010-07-23  121.8  121.95  120.25  120.35  120.65                281312   \n",
       " 2033  2010-07-22  120.3  122.00  120.25  120.75  120.90                293312   \n",
       " 2034  2010-07-21  122.1  123.00  121.05  121.10  121.55                658666   \n",
       " \n",
       "       Turnover (Lacs)  \n",
       " 2030           694.98  \n",
       " 2031           780.01  \n",
       " 2032           340.31  \n",
       " 2033           355.17  \n",
       " 2034           803.56  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head(),dataset_train.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2035, (2035, 1), array([[0.6202352 ],\n",
       "        [0.62226277],\n",
       "        [0.64436334],\n",
       "        ...,\n",
       "        [0.16504461],\n",
       "        [0.15896188],\n",
       "        [0.16626115]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set_scaled), training_set_scaled.shape, training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 2035):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6202352 ],\n",
       "       [0.62226277],\n",
       "       [0.64436334],\n",
       "       ...,\n",
       "       [0.16504461],\n",
       "       [0.15896188],\n",
       "       [0.16626115]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6202352 , 0.62226277, 0.64436334, 0.61719384, 0.61820762,\n",
       "       0.62408759, 0.62793998, 0.63584753, 0.61658556, 0.57725061,\n",
       "       0.54845904, 0.57339822, 0.57339822, 0.56731549, 0.57948094,\n",
       "       0.57137064, 0.63706407, 0.62814274, 0.63219789, 0.62550689,\n",
       "       0.61942417, 0.63219789, 0.61111111, 0.62206002, 0.64557989,\n",
       "       0.67234388, 0.66058394, 0.64760746, 0.6283455 , 0.62408759,\n",
       "       0.61597729, 0.63341444, 0.63077859, 0.63321168, 0.64841849,\n",
       "       0.62469586, 0.62814274, 0.61394972, 0.67964315, 0.65815085,\n",
       "       0.6593674 , 0.64841849, 0.62773723, 0.67883212, 0.66058394,\n",
       "       0.63990268, 0.60888078, 0.6431468 , 0.6784266 , 0.65064882,\n",
       "       0.71695053, 0.74574209, 0.7676399 , 0.78548256, 0.78994323,\n",
       "       0.75892133, 0.76520681, 0.79622871, 0.81062449, 0.74371452])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled[0:60, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1975, 60),\n",
       " array([[0.6202352 , 0.62226277, 0.64436334, ..., 0.79622871, 0.81062449,\n",
       "         0.74371452],\n",
       "        [0.62226277, 0.64436334, 0.61719384, ..., 0.81062449, 0.74371452,\n",
       "         0.77007299],\n",
       "        [0.64436334, 0.61719384, 0.61820762, ..., 0.74371452, 0.77007299,\n",
       "         0.73641525],\n",
       "        ...,\n",
       "        [0.19870235, 0.21796431, 0.21553122, ..., 0.14963504, 0.14801298,\n",
       "         0.15815085],\n",
       "        [0.21796431, 0.21553122, 0.20600162, ..., 0.14801298, 0.15815085,\n",
       "         0.16504461],\n",
       "        [0.21553122, 0.20600162, 0.21654501, ..., 0.15815085, 0.16504461,\n",
       "         0.15896188]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1975, 60, 1), array([[[0.6202352 ],\n",
       "         [0.62226277],\n",
       "         [0.64436334],\n",
       "         ...,\n",
       "         [0.79622871],\n",
       "         [0.81062449],\n",
       "         [0.74371452]],\n",
       " \n",
       "        [[0.62226277],\n",
       "         [0.64436334],\n",
       "         [0.61719384],\n",
       "         ...,\n",
       "         [0.81062449],\n",
       "         [0.74371452],\n",
       "         [0.77007299]],\n",
       " \n",
       "        [[0.64436334],\n",
       "         [0.61719384],\n",
       "         [0.61820762],\n",
       "         ...,\n",
       "         [0.74371452],\n",
       "         [0.77007299],\n",
       "         [0.73641525]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.19870235],\n",
       "         [0.21796431],\n",
       "         [0.21553122],\n",
       "         ...,\n",
       "         [0.14963504],\n",
       "         [0.14801298],\n",
       "         [0.15815085]],\n",
       " \n",
       "        [[0.21796431],\n",
       "         [0.21553122],\n",
       "         [0.20600162],\n",
       "         ...,\n",
       "         [0.14801298],\n",
       "         [0.15815085],\n",
       "         [0.16504461]],\n",
       " \n",
       "        [[0.21553122],\n",
       "         [0.20600162],\n",
       "         [0.21654501],\n",
       "         ...,\n",
       "         [0.15815085],\n",
       "         [0.16504461],\n",
       "         [0.15896188]]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahsood\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1], 1 \n",
    "# 3D Shape has Time-steps and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#50 is the dimensionality of the output space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 60, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 60, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 71,051\n",
      "Trainable params: 71,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(regressor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1975/1975 [==============================] - 10s 5ms/step - loss: 0.0113\n",
      "Epoch 2/100\n",
      "1975/1975 [==============================] - 7s 3ms/step - loss: 0.0026\n",
      "Epoch 3/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0026\n",
      "Epoch 4/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0025\n",
      "Epoch 5/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0026\n",
      "Epoch 6/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0023\n",
      "Epoch 7/100\n",
      "1975/1975 [==============================] - 7s 3ms/step - loss: 0.0022\n",
      "Epoch 8/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0019\n",
      "Epoch 9/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0018\n",
      "Epoch 10/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0020\n",
      "Epoch 11/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0018\n",
      "Epoch 12/100\n",
      "1975/1975 [==============================] - 10s 5ms/step - loss: 0.0016\n",
      "Epoch 13/100\n",
      "1975/1975 [==============================] - 9s 4ms/step - loss: 0.0018\n",
      "Epoch 14/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0017\n",
      "Epoch 15/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0016\n",
      "Epoch 16/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0015\n",
      "Epoch 17/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0015\n",
      "Epoch 18/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0014\n",
      "Epoch 19/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0016\n",
      "Epoch 20/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 0.0015\n",
      "Epoch 21/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0013\n",
      "Epoch 22/100\n",
      "1975/1975 [==============================] - 9s 5ms/step - loss: 0.0013\n",
      "Epoch 23/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0013\n",
      "Epoch 24/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0012\n",
      "Epoch 25/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0012\n",
      "Epoch 26/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0012\n",
      "Epoch 27/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0012\n",
      "Epoch 28/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0011\n",
      "Epoch 29/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0011\n",
      "Epoch 30/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0012\n",
      "Epoch 31/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0012\n",
      "Epoch 32/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0013\n",
      "Epoch 33/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0011\n",
      "Epoch 34/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0011\n",
      "Epoch 35/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 9.7920e-04\n",
      "Epoch 36/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 9.7150e-04\n",
      "Epoch 37/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0010\n",
      "Epoch 38/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 9.4935e-04\n",
      "Epoch 39/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.0845e-04\n",
      "Epoch 40/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 9.8721e-04\n",
      "Epoch 41/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.9915e-04\n",
      "Epoch 42/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 0.0011\n",
      "Epoch 43/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.4787e-04\n",
      "Epoch 44/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.2065e-04\n",
      "Epoch 45/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 9.2054e-04\n",
      "Epoch 46/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.9434e-04\n",
      "Epoch 47/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.9501e-04\n",
      "Epoch 48/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 6.9494e-04\n",
      "Epoch 49/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.6841e-04\n",
      "Epoch 50/100\n",
      "1975/1975 [==============================] - 9s 4ms/step - loss: 8.6769e-04\n",
      "Epoch 51/100\n",
      "1975/1975 [==============================] - 9s 4ms/step - loss: 7.8934e-04\n",
      "Epoch 52/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.1006e-04\n",
      "Epoch 53/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.9499e-04\n",
      "Epoch 54/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.3034e-04\n",
      "Epoch 55/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.6880e-04\n",
      "Epoch 56/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.2873e-04\n",
      "Epoch 57/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 9.0646e-04\n",
      "Epoch 58/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.4979e-04\n",
      "Epoch 59/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.6474e-04\n",
      "Epoch 60/100\n",
      "1975/1975 [==============================] - 11s 5ms/step - loss: 7.1390e-04\n",
      "Epoch 61/100\n",
      "1975/1975 [==============================] - 9s 4ms/step - loss: 7.6266e-04\n",
      "Epoch 62/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.1383e-04\n",
      "Epoch 63/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.9528e-04\n",
      "Epoch 64/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.7192e-04\n",
      "Epoch 65/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.8589e-04\n",
      "Epoch 66/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.3411e-04\n",
      "Epoch 67/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.6981e-04\n",
      "Epoch 68/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.7432e-04\n",
      "Epoch 69/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.4239e-04\n",
      "Epoch 70/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.5051e-04\n",
      "Epoch 71/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.5458e-04\n",
      "Epoch 72/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.2527e-04\n",
      "Epoch 73/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 8.3921e-04\n",
      "Epoch 74/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.0872e-04\n",
      "Epoch 75/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.3030e-04\n",
      "Epoch 76/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.5671e-04\n",
      "Epoch 77/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 6.6597e-04\n",
      "Epoch 78/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.3574e-04\n",
      "Epoch 79/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.9506e-04\n",
      "Epoch 80/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.1066e-04\n",
      "Epoch 81/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.4428e-04\n",
      "Epoch 82/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.8907e-04\n",
      "Epoch 83/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.2598e-04\n",
      "Epoch 84/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 5.6355e-04\n",
      "Epoch 85/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.2347e-04\n",
      "Epoch 86/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 6.1779e-04\n",
      "Epoch 87/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.3798e-04\n",
      "Epoch 88/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.1435e-04\n",
      "Epoch 89/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.1930e-04\n",
      "Epoch 90/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.7193e-04\n",
      "Epoch 91/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.0130e-04\n",
      "Epoch 92/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.2358e-04\n",
      "Epoch 93/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.1408e-04\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975/1975 [==============================] - 8s 4ms/step - loss: 7.3653e-04\n",
      "Epoch 95/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 5.6176e-04\n",
      "Epoch 96/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.2735e-04\n",
      "Epoch 97/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.1815e-04\n",
      "Epoch 98/100\n",
      "1975/1975 [==============================] - 8s 4ms/step - loss: 6.7295e-04\n",
      "Epoch 99/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 6.4010e-04\n",
      "Epoch 100/100\n",
      "1975/1975 [==============================] - 7s 4ms/step - loss: 6.5149e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe4ff748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('tatatest.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220.1 ],\n",
       "       [221.1 ],\n",
       "       [229.45],\n",
       "       [230.3 ],\n",
       "       [237.7 ],\n",
       "       [237.1 ],\n",
       "       [229.7 ],\n",
       "       [226.25],\n",
       "       [215.  ],\n",
       "       [215.  ],\n",
       "       [215.5 ],\n",
       "       [208.  ],\n",
       "       [217.  ],\n",
       "       [223.5 ],\n",
       "       [230.  ],\n",
       "       [234.55]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 76):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhhjgrIEYYwxJihLEMYYY4L6f4UlS7FKzb0uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcc8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real TATA Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted TAT Stock Price')\n",
    "plt.title('TATA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TATA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.6202352 ],\n",
       "        [0.62226277],\n",
       "        [0.64436334],\n",
       "        ...,\n",
       "        [0.79622871],\n",
       "        [0.81062449],\n",
       "        [0.74371452]],\n",
       "\n",
       "       [[0.62226277],\n",
       "        [0.64436334],\n",
       "        [0.61719384],\n",
       "        ...,\n",
       "        [0.81062449],\n",
       "        [0.74371452],\n",
       "        [0.77007299]],\n",
       "\n",
       "       [[0.64436334],\n",
       "        [0.61719384],\n",
       "        [0.61820762],\n",
       "        ...,\n",
       "        [0.74371452],\n",
       "        [0.77007299],\n",
       "        [0.73641525]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.19870235],\n",
       "        [0.21796431],\n",
       "        [0.21553122],\n",
       "        ...,\n",
       "        [0.14963504],\n",
       "        [0.14801298],\n",
       "        [0.15815085]],\n",
       "\n",
       "       [[0.21796431],\n",
       "        [0.21553122],\n",
       "        [0.20600162],\n",
       "        ...,\n",
       "        [0.14801298],\n",
       "        [0.15815085],\n",
       "        [0.16504461]],\n",
       "\n",
       "       [[0.21553122],\n",
       "        [0.20600162],\n",
       "        [0.21654501],\n",
       "        ...,\n",
       "        [0.15815085],\n",
       "        [0.16504461],\n",
       "        [0.15896188]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77007299, 0.73641525, 0.73763179, ..., 0.16504461, 0.15896188,\n",
       "       0.16626115])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [pd.DataFrame(predicted_stock_price, columns=['Predicted']), pd.DataFrame(real_stock_price, columns=['Real'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.878006</td>\n",
       "      <td>220.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.940353</td>\n",
       "      <td>221.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214.690201</td>\n",
       "      <td>229.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219.947403</td>\n",
       "      <td>230.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.322388</td>\n",
       "      <td>237.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226.205154</td>\n",
       "      <td>237.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>229.161453</td>\n",
       "      <td>229.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>225.390656</td>\n",
       "      <td>226.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>221.638260</td>\n",
       "      <td>215.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>214.205719</td>\n",
       "      <td>215.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>211.554504</td>\n",
       "      <td>215.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>211.885666</td>\n",
       "      <td>208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>207.626419</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210.908340</td>\n",
       "      <td>223.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>217.030396</td>\n",
       "      <td>230.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>222.851685</td>\n",
       "      <td>234.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted    Real\n",
       "0   123.878006  220.10\n",
       "1   186.940353  221.10\n",
       "2   214.690201  229.45\n",
       "3   219.947403  230.30\n",
       "4   220.322388  237.70\n",
       "5   226.205154  237.10\n",
       "6   229.161453  229.70\n",
       "7   225.390656  226.25\n",
       "8   221.638260  215.00\n",
       "9   214.205719  215.00\n",
       "10  211.554504  215.50\n",
       "11  211.885666  208.00\n",
       "12  207.626419  217.00\n",
       "13  210.908340  223.50\n",
       "14  217.030396  230.00\n",
       "15  222.851685  234.55"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
